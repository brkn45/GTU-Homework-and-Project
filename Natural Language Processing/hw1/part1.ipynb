{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en co der ça lış ma ör ne ği dir dik ka te al ma yı nı a mi a ne\n",
      "za man çok hız lı ge çi yor\n"
     ]
    }
   ],
   "source": [
    "from syllable import Encoder\n",
    "from collections import Counter\n",
    "import math\n",
    "from itertools import tee\n",
    "import random\n",
    "\n",
    "\n",
    " #download sylable repository\n",
    "from syllable import Encoder #import syllable repository\n",
    "\n",
    "encoder = Encoder(lang=\"tr\", limitby=\"vocabulary\", limit=3000)  # params chosen for demonstration purposes\n",
    "\n",
    "#example about syllable encoder\n",
    "print(encoder.tokenize(\"Encoder çalışma örneğidir. Dikkate almayını \"))\n",
    "print(encoder.tokenize(\"Zaman çok hızlı geçiyor.\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Syllable Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syllable extraction from 'wiki_00' was completed, and the results have been saved to 'syllable.txt'.\n"
     ]
    }
   ],
   "source": [
    "def extract_and_store_syllabic_data(source_path, destination_path):\n",
    "    # Initialize a tokenizer object with language settings and token limits\n",
    "    tokenizer_tool = Encoder(lang=\"tr\", limitby=\"vocabulary\", limit=3000)\n",
    "\n",
    "    try:\n",
    "        # Read content from the source file\n",
    "        with open(source_path, 'r', encoding='utf-8') as source:\n",
    "            raw_content = source.read()\n",
    "\n",
    "            # Perform syllable extraction using the tokenizer\n",
    "            segmented_text = tokenizer_tool.tokenize(raw_content)\n",
    "\n",
    "            # Save the segmented content to the destination file\n",
    "            with open(destination_path, 'w', encoding='utf-8') as destination:\n",
    "                destination.write(segmented_text)\n",
    "\n",
    "            print(\n",
    "                f\"Syllable extraction from '{source_path}' was completed, \"\n",
    "                f\"and the results have been saved to '{destination_path}'.\"\n",
    "            )\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: '{source_path}' was not found.\")\n",
    "    except Exception as error:\n",
    "        print(f\"An unexpected error occurred: {error}\")\n",
    "\n",
    "# Example usage of the function\n",
    "input_filename = \"wiki_00\"\n",
    "output_filename = \"syllable.txt\"\n",
    "\n",
    "extract_and_store_syllabic_data(input_filename, output_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converted from uppercase to lowercase and Turkish characters have been replaced with their English equivalents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file 'syllable.txt' has been converted from uppercase to lowercase, and Turkish characters have been replaced with their English equivalents. The modified content has been saved to 'syllable_output.txt'.\n"
     ]
    }
   ],
   "source": [
    "def lowercase_converter(input_string):\n",
    "    return input_string.lower()\n",
    "\n",
    "def turkish_to_english_mapper(turkish_text):\n",
    "    tr_chars = \"çğıöşü\"\n",
    "    en_chars = \"cgiosu\"\n",
    "    mapping = str.maketrans(tr_chars, en_chars)\n",
    "    return turkish_text.translate(mapping)\n",
    "\n",
    "def file_handler_and_transformer(input_filename):\n",
    "    try:\n",
    "        with open(input_filename, 'r', encoding='utf-8') as source_file:\n",
    "            raw_data = source_file.read()\n",
    "            transformed_lower = lowercase_converter(raw_data)\n",
    "            translated_text = turkish_to_english_mapper(transformed_lower)\n",
    "\n",
    "        output_filename = \"syllable_output.txt\"\n",
    "        with open(output_filename, 'w', encoding='utf-8') as result_file:\n",
    "            result_file.write(translated_text)\n",
    "\n",
    "        print(\n",
    "    f\"The file '{input_filename}' has been converted from uppercase to lowercase, \"\n",
    "    f\"and Turkish characters have been replaced with their English equivalents. \"\n",
    "    f\"The modified content has been saved to '{output_filename}'.\"\n",
    ")\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: '{input_filename}' does not exist or could not be found.\")\n",
    "\n",
    "# Example usage: read input filename and process the file\n",
    "target_file = \"syllable.txt\"\n",
    "file_handler_and_transformer(target_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide to Wikipedia syllable Train and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content from syllable_output.txt has been successfully saved to text_95_percent.txt and text_5_percent.txt.\n"
     ]
    }
   ],
   "source": [
    "def divide_and_save(input_filename, output_file1, output_file2, split_ratio=0.95):\n",
    "    try:\n",
    "        # Read the input file\n",
    "        with open(input_filename, 'r', encoding='utf-8') as input_file:\n",
    "            content = input_file.read()\n",
    "\n",
    "            # Calculate the split index\n",
    "            split_index = int(len(content) * split_ratio)\n",
    "            content_part1 = content[:split_index]\n",
    "            content_part2 = content[split_index:]\n",
    "\n",
    "            # Write the first part to output_file1\n",
    "            with open(output_file1, 'w', encoding='utf-8') as file1:\n",
    "                file1.write(content_part1)\n",
    "\n",
    "            # Write the second part to output_file2\n",
    "            with open(output_file2, 'w', encoding='utf-8') as file2:\n",
    "                file2.write(content_part2)\n",
    "\n",
    "            print(f\"Content from {input_filename} has been successfully saved to {output_file1} and {output_file2}.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {input_filename} not found.\")\n",
    "    except Exception as error:\n",
    "        print(f\"An error occurred: {error}\")\n",
    "\n",
    "# Example of usage\n",
    "input_filename = \"syllable_output.txt\"\n",
    "output_file1 = \"text_95_percent.txt\"\n",
    "output_file2 = \"text_5_percent.txt\"\n",
    "\n",
    "divide_and_save(input_filename, output_file1, output_file2)\n",
    "\n",
    "def read_dataset(file_name):\n",
    "    try:\n",
    "        with open(file_name, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{file_name} dosyası bulunamadı.\")\n",
    "        return None\n",
    "\n",
    "file_name = \"text_95_percent.txt\"\n",
    "dataset_95 = read_dataset(file_name)\n",
    "\n",
    "file_name = \"text_5_percent.txt\"\n",
    "dataset_5 = read_dataset(file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokanization , Create N gram and good_turing_smoothing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_string(input_string):\n",
    "    segmented_tokens = []\n",
    "    temp_token = \"\"\n",
    "\n",
    "    for character in input_string:\n",
    "        if character == \" \":\n",
    "            if temp_token:\n",
    "                segmented_tokens.append(temp_token)\n",
    "                segmented_tokens.append(\" \")\n",
    "            temp_token = \"\"\n",
    "        else:\n",
    "            temp_token += character\n",
    "\n",
    "    if temp_token:\n",
    "        segmented_tokens.append(temp_token)\n",
    "\n",
    "    return segmented_tokens\n",
    "\n",
    "\n",
    "def sliding_window(sequence, window_size):\n",
    "    iterables = tee(sequence, window_size)\n",
    "    for shift in range(1, window_size):\n",
    "        for it in iterables[shift:]:\n",
    "            next(it, None)\n",
    "    return zip(*iterables)\n",
    "\n",
    "def generate_ngram_frequency(token_sequence, n):\n",
    "    # Boşluk karakterlerini filtreleyerek ngram frekansı hesapla\n",
    "    filtered_tokens = [token for token in token_sequence if token.strip()]\n",
    "    ngram_freq_table = Counter(map(''.join, sliding_window(filtered_tokens, n)))\n",
    "    return ngram_freq_table\n",
    "\n",
    "\n",
    "def good_turing_smoothing(freq_table, threshold=5):\n",
    "    total_count = sum(freq_table.values())\n",
    "\n",
    "    infrequent_keys = [key for key, count in freq_table.items() if count <= threshold]\n",
    "    for key in infrequent_keys:\n",
    "        freq_table[key] += threshold\n",
    "\n",
    "    for key in freq_table:\n",
    "        freq_table[key] = (freq_table[key] - threshold) / total_count\n",
    "\n",
    "    return freq_table\n",
    "\n",
    "tokens_95 = tokenize_string(dataset_95)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create One-Gram  Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le: 3102700\n",
      "la: 3100303\n",
      "ri: 2838302\n",
      "si: 2813910\n",
      "da: 2577927\n",
      "a: 2470544\n",
      "de: 2463675\n",
      "li: 2320910\n",
      "di: 2206999\n",
      "ki: 2032904\n",
      "ya: 1998655\n",
      "i: 1983712\n",
      "o: 1889967\n",
      "ve: 1804155\n",
      "ma: 1709854\n",
      "ra: 1633537\n",
      "ta: 1632511\n",
      "ni: 1613517\n",
      "ti: 1458910\n",
      "gi: 1441334\n",
      "ka: 1410048\n",
      "sa: 1186316\n",
      "ne: 1174316\n",
      "te: 1130727\n",
      "bir: 1129599\n",
      "e: 1116526\n",
      "nin: 1093917\n",
      "na: 1077230\n",
      "dir: 1076400\n",
      "bu: 1075638\n",
      "re: 975631\n",
      "me: 936421\n",
      "se: 908965\n",
      "ye: 881004\n",
      "ci: 859904\n",
      "ge: 827471\n",
      "u: 818653\n",
      "lan: 807566\n",
      "ce: 791932\n",
      "lu: 790251\n",
      "mi: 790232\n",
      "rin: 790056\n",
      "mis: 779460\n",
      "du: 778162\n",
      "lar: 767801\n",
      "bi: 760503\n",
      "yi: 743551\n",
      "ler: 715333\n",
      "ha: 698360\n",
      "tir: 690862\n",
      "ca: 687544\n",
      "lik: 665851\n",
      "ba: 659802\n",
      "gu: 655390\n",
      "sin: 633541\n",
      "dan: 632437\n",
      "su: 617669\n",
      "wi: 601694\n",
      "nu: 596410\n",
      "cu: 588850\n",
      "ku: 567478\n",
      "ko: 556921\n",
      "rak: 542120\n",
      "in: 518764\n",
      "den: 513266\n",
      "ol: 508579\n",
      "ke: 446428\n",
      "ru: 433478\n",
      "mu: 430535\n",
      "tur: 427281\n",
      "be: 423810\n",
      "al: 414904\n",
      "lin: 404810\n",
      "pe: 395191\n",
      "zi: 393611\n",
      "is: 387083\n",
      "do: 382027\n",
      "go: 379474\n",
      "an: 373293\n",
      "yo: 369880\n",
      "mak: 362744\n",
      "man: 358817\n",
      "cin: 356623\n",
      "tu: 352056\n",
      "bas: 349255\n",
      "pa: 342165\n",
      "len: 341018\n",
      "son: 322891\n",
      "id: 314251\n",
      "pi: 311330\n",
      "nun: 307218\n",
      "tan: 305326\n",
      "ro: 304847\n",
      "ga: 300023\n",
      "va: 299210\n",
      "rid: 297816\n",
      "ze: 296564\n",
      "tit: 294742\n",
      "za: 292405\n",
      "org: 291252\n"
     ]
    }
   ],
   "source": [
    "unigram = generate_ngram_frequency(tokens_95, 1)\n",
    "\n",
    "unigram = unigram.most_common()\n",
    "\n",
    "for i, item in enumerate(list(unigram)):\n",
    "    if i >= 100:  # İlk 100 öğeden sonra dur\n",
    "        break\n",
    "    print(f'{item[0]}: {item[1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Gram Good-Turing-Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le: 0.023067242678311405\n",
      "la: 0.02304942198349612\n",
      "ri: 0.021101553872399068\n",
      "si: 0.02092020953033213\n",
      "da: 0.01916577439282878\n",
      "a: 0.018367426595019096\n",
      "de: 0.01831635844621384\n",
      "li: 0.01725496024208191\n",
      "di: 0.016408079488179534\n",
      "ki: 0.01511375580696671\n",
      "ya: 0.014859128782882973\n",
      "i: 0.014748033813077044\n",
      "o: 0.014051078854604394\n",
      "ve: 0.013413102440966811\n",
      "ma: 0.012712013854493618\n",
      "ra: 0.012144628803922843\n",
      "ta: 0.01213700092203695\n",
      "ni: 0.011995788457572397\n",
      "ti: 0.010846349924695112\n",
      "gi: 0.010715679698548487\n",
      "ka: 0.010483081343107926\n",
      "sa: 0.008819727278688457\n",
      "ne: 0.008730512285871007\n",
      "te: 0.008406446259044355\n",
      "bir: 0.008398060049719516\n",
      "e: 0.00830086774962764\n",
      "nin: 0.008132779268576829\n",
      "na: 0.00800871838648143\n",
      "dir: 0.008002547682811558\n",
      "bu: 0.007996882530767649\n",
      "re: 0.007253372215209759\n",
      "me: 0.006961862226178742\n",
      "se: 0.006757738322612417\n",
      "ye: 0.006549859954765025\n",
      "ci: 0.006392990259061009\n",
      "ge: 0.006151864437223647\n",
      "u: 0.006086306286668291\n",
      "lan: 0.0060038790678877026\n",
      "ce: 0.0058876468014120355\n",
      "lu: 0.005875149267834858\n",
      "mi: 0.005875008010762897\n",
      "rin: 0.005873699524201574\n",
      "mis: 0.005794922685543766\n",
      "du: 0.005785272597154012\n",
      "lar: 0.005708242885438879\n",
      "bi: 0.0056539853006404\n",
      "yi: 0.005527954254120283\n",
      "ler: 0.00531816519851005\n",
      "ha: 0.005191978025752502\n",
      "tir: 0.005136233524407066\n",
      "ca: 0.005111565578893041\n",
      "lik: 0.004950287175627297\n",
      "ba: 0.004905315384664567\n",
      "gu: 0.0048725140056386845\n",
      "sin: 0.004710075807466314\n",
      "dan: 0.004701868028127108\n",
      "su: 0.0045920741102997665\n",
      "wi: 0.004473306651111537\n",
      "nu: 0.00443402231594092\n",
      "cu: 0.004377816870465926\n",
      "ku: 0.004218924968258049\n",
      "ko: 0.004140438078326898\n",
      "rak: 0.004030398819269309\n",
      "in: 0.0038567567049156122\n",
      "den: 0.0038158813690397507\n",
      "ol: 0.0037810354797618018\n",
      "ke: 0.003318968728212026\n",
      "ru: 0.0032226908817965284\n",
      "mu: 0.003200810904808049\n",
      "tur: 0.0031766187725890504\n",
      "be: 0.003150813335916603\n",
      "al: 0.0030846009420805857\n",
      "lin: 0.0030095562639556412\n",
      "pe: 0.0029380430126297206\n",
      "zi: 0.002926296371908756\n",
      "is: 0.0028777634158160636\n",
      "do: 0.002840174165508978\n",
      "go: 0.0028211936757870657\n",
      "an: 0.0027752405199033443\n",
      "yo: 0.002749866289029515\n",
      "mak: 0.0026968131066340715\n",
      "man: 0.002667617500234561\n",
      "cin: 0.0026513060257144375\n",
      "tu: 0.002617352286364663\n",
      "bas: 0.0025965280201245234\n",
      "pa: 0.00254381682853488\n",
      "len: 0.002535289362138079\n",
      "son: 0.0024005226809045866\n",
      "id: 0.0023362878860760227\n",
      "pi: 0.0023145714699077087\n",
      "nun: 0.0022840004657022623\n",
      "tan: 0.0022699342351680447\n",
      "ro: 0.0022663730700380816\n",
      "ga: 0.0022305086429254667\n",
      "va: 0.0022244643271620845\n",
      "rid: 0.002214100518829791\n",
      "ze: 0.002204792421245837\n",
      "tit: 0.002191246611503054\n",
      "za: 0.0021738719916518556\n",
      "org: 0.002165299917758646\n"
     ]
    }
   ],
   "source": [
    "gt_smooth_unigram = good_turing_smoothing(dict(unigram))\n",
    "\n",
    "for i, item in enumerate(gt_smooth_unigram.items()):\n",
    "    if i >= 100:  # İlk 100 öğeden sonra dur\n",
    "        break\n",
    "    print(f'{item[0]}: {item[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Two-Gram Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leri: 690466\n",
      "lari: 682277\n",
      "wiki: 594639\n",
      "mistir: 451020\n",
      "ola: 411135\n",
      "ile: 406326\n",
      "larak: 376701\n",
      "dia: 343723\n",
      "larin: 320354\n",
      "sinda: 314093\n",
      "kipe: 295616\n",
      "pedi: 292747\n",
      "title: 289535\n",
      "kicu: 289381\n",
      "aorg: 289357\n",
      "orgwi: 289321\n",
      "trwi: 289042\n",
      "curid: 289016\n",
      "idurl: 289013\n",
      "urltr: 289013\n",
      "ridtit: 289013\n",
      "icin: 287640\n",
      "ligi: 286366\n",
      "lerin: 283562\n",
      "masi: 264736\n",
      "digi: 246687\n",
      "yilin: 233454\n",
      "olan: 232975\n",
      "ara: 231385\n",
      "linda: 221636\n",
      "oldu: 221568\n",
      "sonra: 214546\n",
      "tadir: 209522\n",
      "rini: 208912\n",
      "makta: 199603\n",
      "rinin: 186830\n",
      "sinde: 186703\n",
      "tara: 186396\n",
      "daki: 183806\n",
      "rafin: 180322\n",
      "sine: 180107\n",
      "sini: 175125\n",
      "dugu: 170869\n",
      "findan: 170518\n",
      "daha: 170144\n",
      "sinin: 166689\n",
      "rine: 166576\n",
      "rinde: 158170\n",
      "rasin: 151466\n",
      "mesi: 150367\n",
      "mekte: 147656\n",
      "lara: 144149\n",
      "ise: 143359\n",
      "lama: 142394\n",
      "deki: 138922\n",
      "rinda: 136330\n",
      "tedir: 133776\n",
      "kulla: 132004\n",
      "gini: 131522\n",
      "lani: 130289\n",
      "uze: 128192\n",
      "tari: 127992\n",
      "yapi: 127435\n",
      "kara: 126654\n",
      "tesi: 126400\n",
      "kisi: 121713\n",
      "vardir: 120427\n",
      "buyuk: 119835\n",
      "gore: 119548\n",
      "larda: 118891\n",
      "yasa: 116046\n",
      "halle: 115072\n",
      "mahal: 115036\n",
      "sina: 114702\n",
      "mustur: 113952\n",
      "gibi: 113700\n",
      "daya: 111900\n",
      "yeni: 111785\n",
      "basla: 111335\n",
      "iki: 111059\n",
      "ladi: 109129\n",
      "libir: 106737\n",
      "sii: 106177\n",
      "yada: 105365\n",
      "maya: 103715\n",
      "tigi: 103479\n",
      "karsi: 103405\n",
      "olma: 102939\n",
      "bulu: 101979\n",
      "ria: 101821\n",
      "bulun: 101691\n",
      "gunu: 99939\n",
      "sira: 98995\n",
      "kendi: 98875\n",
      "ilce: 98155\n",
      "rii: 97642\n",
      "lerde: 96862\n",
      "cesi: 93548\n",
      "ayri: 93406\n",
      "dirid: 92422\n"
     ]
    }
   ],
   "source": [
    "bigram = generate_ngram_frequency(tokens_95, 2)\n",
    "\n",
    "bigram = bigram.most_common()\n",
    "\n",
    "for i, item in enumerate(list(bigram)):\n",
    "    if i >= 100:  # İlk 100 öğeden sonra dur\n",
    "        break\n",
    "    print(f'{item[0]}: {item[1]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two-Gram Good-Turing-Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leri: 0.005133289467807956\n",
      "lari: 0.00507240766934015\n",
      "wiki: 0.004420855702784829\n",
      "mistir: 0.0033531083570591314\n",
      "ola: 0.003056580022477569\n",
      "ile: 0.003020827113840168\n",
      "larak: 0.002800577598684626\n",
      "dia: 0.0025553999274340114\n",
      "larin: 0.0023816611622130878\n",
      "sinda: 0.002335113239364519\n",
      "kipe: 0.002197744453152571\n",
      "pedi: 0.0021764146351278876\n",
      "title: 0.0021525347552062133\n",
      "kicu: 0.0021513898294565443\n",
      "aorg: 0.0021512113994695825\n",
      "orgwi: 0.0021509437544891406\n",
      "trwi: 0.0021488695058907137\n",
      "curid: 0.002148676206738172\n",
      "idurl: 0.002148653902989802\n",
      "urltr: 0.002148653902989802\n",
      "ridtit: 0.002148653902989802\n",
      "icin: 0.002138446220819049\n",
      "ligi: 0.0021289745623445117\n",
      "lerin: 0.0021081279922011823\n",
      "masi: 0.0019681645365955034\n",
      "digi: 0.0018339777518177015\n",
      "yilin: 0.0017355959177568312\n",
      "olan: 0.001732034752600392\n",
      "ara: 0.0017202137659641959\n",
      "linda: 0.0016477340183438964\n",
      "oldu: 0.0016472284667141722\n",
      "sonra: 0.0015950228263623674\n",
      "tadir: 0.0015576714824251036\n",
      "rini: 0.0015531363869231666\n",
      "makta: 0.0014839278557304935\n",
      "rinin: 0.0013889659297530508\n",
      "sinde: 0.0013880217377387131\n",
      "tara: 0.0013857393208221646\n",
      "daki: 0.0013664837513959079\n",
      "rafin: 0.0013405816649553373\n",
      "sine: 0.0013389832296554743\n",
      "sini: 0.0013019441381953928\n",
      "dugu: 0.0012703025538408955\n",
      "findan: 0.0012676930152815842\n",
      "daha: 0.0012649124813181017\n",
      "sinin: 0.0012392259977784426\n",
      "rine: 0.0012383858899231658\n",
      "rinde: 0.0011758907869899172\n",
      "rasin: 0.0011260493439653517\n",
      "mesi: 0.0011178787374790753\n",
      "mekte: 0.0010977235835352213\n",
      "lara: 0.0010716505016904793\n",
      "ise: 0.0010657771812863314\n",
      "lama: 0.001058602808893923\n",
      "deki: 0.001032789937446833\n",
      "rinda: 0.0010135194988549962\n",
      "tedir: 0.0009945315744091818\n",
      "kulla: 0.0009813574937051945\n",
      "gini: 0.0009777740248003853\n",
      "lani: 0.0009686071842202408\n",
      "uze: 0.0009530168641094839\n",
      "tari: 0.0009515299475514719\n",
      "yapi: 0.0009473888849374081\n",
      "kara: 0.0009415824757783709\n",
      "tesi: 0.0009396940917496955\n",
      "kisi: 0.000904848202212682\n",
      "vardir: 0.0008952873287446642\n",
      "buyuk: 0.0008908860557329484\n",
      "gore: 0.0008887523304722011\n",
      "larda: 0.0008838678095791314\n",
      "yasa: 0.0008627164215414092\n",
      "halle: 0.0008554751379038903\n",
      "mahal: 0.0008552074929234481\n",
      "sina: 0.0008527243422715679\n",
      "mustur: 0.0008471484051790225\n",
      "gibi: 0.0008452748903159273\n",
      "daya: 0.0008318926412938185\n",
      "yeni: 0.0008310376642729615\n",
      "basla: 0.0008276921020174343\n",
      "iki: 0.0008256401571673775\n",
      "ladi: 0.0008112914123825608\n",
      "libir: 0.0007935078903487361\n",
      "sii: 0.0007893445239863022\n",
      "yada: 0.0007833076427607731\n",
      "maya: 0.0007710405811571733\n",
      "tigi: 0.0007692860196187191\n",
      "karsi: 0.0007687358604922546\n",
      "olma: 0.0007652713449120864\n",
      "bulu: 0.0007581341454336283\n",
      "ria: 0.0007569594813527987\n",
      "bulun: 0.0007559929855900909\n",
      "gunu: 0.0007429675965419049\n",
      "sira: 0.0007359493503880879\n",
      "kendi: 0.0007350572004532806\n",
      "ilce: 0.000729704300844437\n",
      "rii: 0.0007258903598731359\n",
      "lerde: 0.0007200913852968888\n",
      "cesi: 0.0006954531779306283\n",
      "ayri: 0.0006943974671744398\n",
      "dirid: 0.0006870818377090202\n"
     ]
    }
   ],
   "source": [
    "gt_smooth_bigram = good_turing_smoothing(dict(bigram))\n",
    "\n",
    "for i, item in enumerate(gt_smooth_bigram.items()):\n",
    "    if i >= 100:  # İlk 100 öğeden sonra dur\n",
    "        break\n",
    "    print(f'{item[0]}: {item[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Tri-Gram Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "olarak: 345861\n",
      "kipedi: 291456\n",
      "pedia: 289937\n",
      "wikipe: 289690\n",
      "diaorg: 289345\n",
      "orgwiki: 289319\n",
      "aorgwi: 289309\n",
      "trwiki: 289042\n",
      "wikicu: 289016\n",
      "idurltr: 289013\n",
      "urltrwi: 289013\n",
      "kicurid: 289013\n",
      "curidtit: 289013\n",
      "ridtitle: 289013\n",
      "yilinda: 205635\n",
      "maktadir: 180281\n",
      "tarafin: 174392\n",
      "rafindan: 169694\n",
      "rasinda: 147933\n",
      "mektedir: 129956\n",
      "larinda: 119336\n",
      "oldugu: 114181\n",
      "mahalle: 113473\n",
      "arasin: 111380\n",
      "diridurl: 92283\n",
      "lerinde: 90268\n",
      "lerini: 89548\n",
      "larini: 85652\n",
      "lerinin: 80297\n",
      "tarihin: 77291\n",
      "turkiye: 76929\n",
      "rihinde: 74189\n",
      "larina: 73201\n",
      "larinin: 71540\n",
      "kullani: 71187\n",
      "lerine: 68893\n",
      "ilcesi: 65704\n",
      "ameri: 65679\n",
      "ayrica: 60085\n",
      "birlikte: 59263\n",
      "univer: 58645\n",
      "lerinden: 58377\n",
      "cesine: 57621\n",
      "bulunan: 57374\n",
      "icinde: 56981\n",
      "niversi: 55539\n",
      "versite: 54663\n",
      "tiridurl: 53878\n",
      "istanbul: 53253\n",
      "malari: 51564\n",
      "onemli: 51422\n",
      "riara: 50535\n",
      "uzerin: 50270\n",
      "calisma: 50006\n",
      "yapilan: 49706\n",
      "basladi: 49568\n",
      "larindan: 49133\n",
      "sebeke: 48965\n",
      "mistirid: 48271\n",
      "bekesi: 47998\n",
      "ikinci: 47348\n",
      "nebagli: 47287\n",
      "dahason: 47074\n",
      "hasonra: 47054\n",
      "olmustur: 46571\n",
      "dirmahal: 46443\n",
      "avrupa: 45473\n",
      "oyuncu: 45219\n",
      "sitesi: 44776\n",
      "merkezi: 44522\n",
      "laria: 43662\n",
      "iceri: 43427\n",
      "risinde: 42952\n",
      "ekono: 42375\n",
      "uzeri: 42361\n",
      "masina: 42339\n",
      "dugunu: 42285\n",
      "bulunmak: 42059\n",
      "ozellik: 41740\n",
      "hallenin: 41688\n",
      "ligini: 41646\n",
      "siile: 41407\n",
      "aile: 40818\n",
      "zerine: 40666\n",
      "zerinde: 40479\n",
      "riile: 40251\n",
      "acenter: 39344\n",
      "larii: 39307\n",
      "dirkoyun: 38968\n",
      "siyoktur: 38697\n",
      "yeralan: 38488\n",
      "rilmistir: 38421\n",
      "lunmakta: 38115\n",
      "sinebag: 38078\n",
      "dilmistir: 37621\n",
      "merika: 37611\n",
      "larara: 37373\n",
      "alani: 37350\n",
      "okulu: 37346\n",
      "ingiliz: 37120\n"
     ]
    }
   ],
   "source": [
    "trigram = generate_ngram_frequency(tokens_95, 3)\n",
    "\n",
    "trigram = trigram.most_common()\n",
    "\n",
    "for i, item in enumerate(list(trigram)):\n",
    "    if i >= 100:  # İlk 100 öğeden sonra dur\n",
    "        break\n",
    "    print(f'{item[0]}: {item[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three-Gram Good-Turing-Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "olarak: 0.0025712950845556666\n",
      "kipedi: 0.002166816604855297\n",
      "pedia: 0.0021555234735132355\n",
      "wikipe: 0.002153687131550438\n",
      "diaorg: 0.002151122200468798\n",
      "orgwiki: 0.0021509289013148195\n",
      "aorgwi: 0.002150854555486366\n",
      "trwiki: 0.002148869521866662\n",
      "wikicu: 0.0021486762227126833\n",
      "idurltr: 0.0021486539189641473\n",
      "urltrwi: 0.0021486539189641473\n",
      "kicurid: 0.0021486539189641473\n",
      "curidtit: 0.0021486539189641473\n",
      "ridtitle: 0.0021486539189641473\n",
      "yilinda: 0.0015287732704859299\n",
      "maktadir: 0.001340276857025344\n",
      "tarafin: 0.001296494598649175\n",
      "rafindan: 0.001261566928441798\n",
      "rasinda: 0.0010997829711444957\n",
      "mektedir: 0.000966131475333935\n",
      "larinda: 0.0008871762055164932\n",
      "oldugu: 0.0008488509309487989\n",
      "mahalle: 0.0008435872462943028\n",
      "arasin: 0.0008280266643990198\n",
      "diridurl: 0.0006860484358016857\n",
      "lerinde: 0.0006710677513683387\n",
      "lerini: 0.0006657148517196985\n",
      "larini: 0.0006367497169542792\n",
      "lerinin: 0.0005969375258175183\n",
      "tarihin: 0.0005745891697844457\n",
      "turkiye: 0.000571897850794435\n",
      "rihinde: 0.0005515270937982212\n",
      "larina: 0.0005441817259470317\n",
      "larinin: 0.0005318328838409327\n",
      "kullani: 0.00052920847609653\n",
      "lerine: 0.0005121535430493349\n",
      "ilcesi: 0.0004884446583555663\n",
      "ameri: 0.000488258793784433\n",
      "ayrica: 0.00044666973734763734\n",
      "birlikte: 0.0004405585102487732\n",
      "univer: 0.00043596393805035705\n",
      "lerinden: 0.0004339714698478077\n",
      "cesine: 0.00042835092521673556\n",
      "bulunan: 0.00042651458325393816\n",
      "icinde: 0.00042359279219572214\n",
      "niversi: 0.0004128721237327512\n",
      "versite: 0.00040635942916023905\n",
      "tiridurl: 0.00040052328162665224\n",
      "istanbul: 0.0003958766673483188\n",
      "malari: 0.0003833196569225505\n",
      "onemli: 0.0003822639461585131\n",
      "riara: 0.0003756694711747023\n",
      "uzerin: 0.0003736993067206889\n",
      "calisma: 0.0003717365768495209\n",
      "yapilan: 0.0003695062019959208\n",
      "basladi: 0.0003684802295632648\n",
      "larindan: 0.00036524618602554475\n",
      "sebeke: 0.0003639971761075287\n",
      "mistirid: 0.00035883757561286725\n",
      "bekesi: 0.0003568079344960912\n",
      "ikinci: 0.0003519754556466244\n",
      "nebagli: 0.0003515219460930591\n",
      "dahason: 0.000349938379947003\n",
      "hasonra: 0.00034978968829009634\n",
      "olmustur: 0.00034619878477580026\n",
      "dirmahal: 0.0003452471581715976\n",
      "avrupa: 0.0003380356128116241\n",
      "oyuncu: 0.0003361472287689094\n",
      "sitesi: 0.0003328537085684266\n",
      "merkezi: 0.0003309653245257119\n",
      "laria: 0.0003245715832787251\n",
      "iceri: 0.0003228244563100717\n",
      "risinde: 0.00031929302945853826\n",
      "ekono: 0.00031500327515678083\n",
      "uzeri: 0.00031489919099694617\n",
      "masina: 0.00031473563017434886\n",
      "dugunu: 0.00031433416270070083\n",
      "bulunmak: 0.00031265394697765545\n",
      "ozellik: 0.00031028231504999406\n",
      "hallenin: 0.00030989571674203673\n",
      "ligini: 0.0003095834642625327\n",
      "siile: 0.000307806598962498\n",
      "aile: 0.0003034276296665966\n",
      "zerine: 0.0003022975730741059\n",
      "zerinde: 0.00030090730608202854\n",
      "riile: 0.0002992122211932925\n",
      "acenter: 0.000292469054552575\n",
      "larii: 0.00029219397498729766\n",
      "dirkoyun: 0.00028967365140272956\n",
      "siyoktur: 0.0002876588794516442\n",
      "yeralan: 0.0002861050516369695\n",
      "rilmistir: 0.00028560693458633214\n",
      "lunmakta: 0.0002833319522356601\n",
      "sinebag: 0.00028305687267038274\n",
      "dilmistir: 0.00027965926831006533\n",
      "merika: 0.000279584922481612\n",
      "larara: 0.00027781549176442264\n",
      "alani: 0.00027764449635898\n",
      "okulu: 0.0002776147580275986\n",
      "ingiliz: 0.00027593454230455324\n"
     ]
    }
   ],
   "source": [
    "gt_smooth_trigram = good_turing_smoothing(dict(trigram))\n",
    "\n",
    "for i, item in enumerate(gt_smooth_trigram.items()):\n",
    "    if i >= 100:  # İlk 100 öğeden sonra dur\n",
    "        break\n",
    "    print(f'{item[0]}: {item[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One gram perplexity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Perplexity: 1707021.107194859\n"
     ]
    }
   ],
   "source": [
    "tokens_5 = tokenize_string(dataset_5)\n",
    "\n",
    "def calculate_unigram_perplexity(token_list, unigram_prob_dist):\n",
    "    cumulative_log_prob = 0\n",
    "    token_count = len(token_list)\n",
    "\n",
    "    for token in token_list:\n",
    "        if token in unigram_prob_dist:\n",
    "            cumulative_log_prob += math.log2(unigram_prob_dist[token])\n",
    "        else:\n",
    "            # Assign a small probability for out-of-vocabulary tokens\n",
    "            cumulative_log_prob += math.log2(1e-10)\n",
    "\n",
    "    mean_log_prob = cumulative_log_prob / token_count\n",
    "    perplexity_score = 2 ** (-mean_log_prob)\n",
    "    return perplexity_score\n",
    "\n",
    "result_perplexity = calculate_unigram_perplexity(tokens_5, gt_smooth_unigram)\n",
    "print(\"Unigram Perplexity:\", result_perplexity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two gram perplexity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Perplexity: 9999983769.663683\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compute_bigram_perplexity(token_sequence, bigram_prob_dist):\n",
    "    cumulative_log_probability = 0\n",
    "    total_tokens = len(token_sequence)\n",
    "\n",
    "    for idx in range(1, total_tokens):\n",
    "        previous_token = token_sequence[idx - 1]\n",
    "        current_token = token_sequence[idx]\n",
    "        bigram = previous_token + \" \" + current_token\n",
    "\n",
    "        if bigram in bigram_prob_dist:\n",
    "            cumulative_log_probability += math.log2(bigram_prob_dist[bigram])\n",
    "        else:\n",
    "            # Assign a small probability for unseen bigrams\n",
    "            cumulative_log_probability += math.log2(1e-10)\n",
    "\n",
    "    mean_log_probability = cumulative_log_probability / total_tokens\n",
    "    perplexity_score = 2 ** (-mean_log_probability)\n",
    "    return perplexity_score\n",
    "\n",
    "result_perplexity = compute_bigram_perplexity(tokens_5, gt_smooth_bigram)\n",
    "print(\"Bigram Perplexity:\", result_perplexity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three gram perplexity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram Perplexity: 9999967497.456444\n"
     ]
    }
   ],
   "source": [
    "def calculate_trigram_perplexity(token_sequence, trigram_prob_dist):\n",
    "    cumulative_log_prob = 0\n",
    "    sequence_length = len(token_sequence)\n",
    "\n",
    "    for idx in range(2, sequence_length):\n",
    "        first_token = token_sequence[idx - 2]\n",
    "        second_token = token_sequence[idx - 1]\n",
    "        third_token = token_sequence[idx]\n",
    "        trigram = f\"{first_token} {second_token} {third_token}\"\n",
    "\n",
    "        if trigram in trigram_prob_dist:\n",
    "            cumulative_log_prob += math.log2(trigram_prob_dist[trigram])\n",
    "        else:\n",
    "            # Assign a small probability for unseen trigrams\n",
    "            cumulative_log_prob += math.log2(1e-10)\n",
    "\n",
    "    mean_log_prob = cumulative_log_prob / sequence_length\n",
    "    perplexity_value = 2 ** (-mean_log_prob)\n",
    "    return perplexity_value\n",
    "\n",
    "trigram_perplexity_result = calculate_trigram_perplexity(tokens_5, gt_smooth_trigram)\n",
    "print(\"Trigram Perplexity:\", trigram_perplexity_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random generated word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 5 Random Words (Unigram):\n",
      "da si le la ri \n",
      "\n",
      "ri da si le la \n",
      "\n",
      "Selected 5 Random Words (Bigram):\n",
      "mistir lari leri ola wiki \n",
      "\n",
      "wiki mistir lari leri ola \n",
      "\n",
      "Selected 5 Random Words (Trigram):\n",
      "olarak kipedi pedia diaorg wikipe \n",
      "\n",
      "olarak diaorg wikipe kipedi pedia "
     ]
    }
   ],
   "source": [
    "random_selection = random.sample(\n",
    "    list(dict(list(gt_smooth_unigram.items())[:5]).keys()), 5\n",
    ")\n",
    "\n",
    "print(\"Selected 5 Random Words (Unigram):\")\n",
    "for token in random_selection:\n",
    "    print(token, end=\" \")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "random_selection = random.sample(\n",
    "    list(dict(list(gt_smooth_unigram.items())[:5]).keys()), 5\n",
    ")\n",
    "\n",
    "\n",
    "for token in random_selection:\n",
    "    print(token, end=\" \")\n",
    "\n",
    "random_selection = random.sample(\n",
    "    list(dict(list(gt_smooth_bigram.items())[:5]).keys()), 5\n",
    ")\n",
    "\n",
    "print(\"\\n\\nSelected 5 Random Words (Bigram):\")\n",
    "for token in random_selection:\n",
    "    print(token, end=\" \")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "random_selection = random.sample(\n",
    "    list(dict(list(gt_smooth_bigram.items())[:5]).keys()) ,5\n",
    ")\n",
    "\n",
    "\n",
    "for token in random_selection:\n",
    "    print(token, end=\" \")\n",
    "\n",
    "random_selection = random.sample(\n",
    "    list(dict(list(gt_smooth_trigram.items())[:5]).keys()), 5\n",
    ")\n",
    "\n",
    "print(\"\\n\\nSelected 5 Random Words (Trigram):\")\n",
    "for token in random_selection:\n",
    "    print(token, end=\" \")\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n",
    "random_selection = random.sample(\n",
    "    list(dict(list(gt_smooth_trigram.items())[:5]).keys()), 5\n",
    ")\n",
    "for token in random_selection:\n",
    "    print(token, end=\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
